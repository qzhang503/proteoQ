---
title: How do I run proteoQ
author: Qiang Zhang
date: '2020-04-15'
slug: how-do-i-run-proteoq
categories: []
tags: []
subtitle: ''
summary: ''
authors: []
lastmod: '2020-04-15T12:04:43-05:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

<script src="/rmarkdown-libs/htmlwidgets/htmlwidgets.js"></script>
<script src="/rmarkdown-libs/d3/d3.min.js"></script>
<script src="/rmarkdown-libs/diagonalNetwork-binding/diagonalNetwork.js"></script>
<script src="/rmarkdown-libs/sankey/sankey.js"></script>
<script src="/rmarkdown-libs/sankeyNetwork-binding/sankeyNetwork.js"></script>


<p>The framework of proteoQ can be divided conceptually into the units of data normalization and informatic analysis.</p>
<div id="data-normalization" class="section level2">
<h2>Data normalization</h2>
<p>The modules in data normalization need to be run in order, starting with the upload of metadata by <code>load_expts</code> and ending with the compilation of protein table by <code>standPrn</code>.</p>
<div id="htmlwidget-1" style="width:600px;height:900px;" class="diagonalNetwork html-widget"></div>
<script type="application/json" data-for="htmlwidget-1">{"x":{"root":{"name":"preprocessing","children":[{"name":"metadata","children":[{"name":"load_expts","children":[{"name":"expt_smry.xlsx","children":[{"name":"Sample_ID"},{"name":"TMT_Set"},{"name":"LCMS_Injection"},{"name":"TMT_Channel"},{"name":"Reference"},{"name":"..."}]},{"name":"frac_smry.xlsx","children":[{"name":"RAW_File"},{"name":"PSM_File"},{"name":"..."},{"name":"extract_psm_raws"},{"name":"extract_raws"}]}]}]},{"name":"normalization","children":[{"name":"normPSM","children":[{"name":"fasta","children":[{"name":"UniProt"},{"name":"RefSeq"}]},{"name":"entrez","children":[{"name":"Uni2Entrez"},{"name":"Ref2Entrez"}]},{"name":"filter_ = ..."}]},{"name":"purgePSM","children":[{"name":"width, height, ..."}]},{"name":"PSM2Pep","children":[{"name":"filter_ = ..."}]},{"name":"mergePep","children":[{"name":"filter_ = ..."}]},{"name":"standPep","children":[{"name":"slice_ = ..."}]},{"name":"purgePep","children":[{"name":"width, height, ..."}]},{"name":"Pep2Prn","children":[{"name":"filter_ = ..."}]},{"name":"standPrn","children":[{"name":"slice_ = ..."}]}]},{"name":"hypothesis tests","children":[{"name":"pepSig","children":[{"name":"grp_1 = ~ Term[...]"},{"name":"grp_2 = ~ Term_2[...]"},{"name":"filter_ = ..."}]},{"name":"prnSig","children":[{"name":"grp_1 = ~ Term[...]"},{"name":"grp_2 = ~ Term_2[...]"},{"name":"filter_ = ..."}]}]}]},"options":{"height":900,"width":600,"fontSize":15,"fontFamily":"serif","linkColour":"#ccc","nodeColour":"#fff","nodeStroke":"function(d, i) { return [\"steelblue\", \"steelblue\", \"steelblue\", \"steelblue\", \"#de2d26\", \"#de2d26\", \"#fdae6b\", \"#de2d26\", \"#de2d26\", \"#de2d26\", \"#fdae6b\", \"#de2d26\", \"#de2d26\", \"#fdae6b\", \"#fdae6b\", \"#fdae6b\", \"#fdae6b\", \"steelblue\", \"steelblue\", \"steelblue\", \"steelblue\", \"steelblue\", \"steelblue\", \"steelblue\", \"steelblue\", \"steelblue\", \"steelblue\", \"steelblue\", \"steelblue\", \"steelblue\", \"steelblue\", \"steelblue\", \"steelblue\", \"steelblue\", \"steelblue\", \"steelblue\", \"steelblue\", \"steelblue\", \"steelblue\", \"steelblue\", \"steelblue\", \"steelblue\", \"steelblue\", \"steelblue\", \"steelblue\", \"steelblue\", \"#fdae6b\", \"#fdae6b\", \"NA\", \"NA\", \"#fdae6b\", \"#fdae6b\", \"#fdae6b\", \"#fdae6b\", \"#fdae6b\"][i]; }","textColour":"#111","margin":{"top":null,"right":null,"bottom":null,"left":null},"opacity":0.9}},"evals":["options.nodeStroke"],"jsHooks":[]}</script>
<p>In stead of putting all components into one large unit, utilities in data normalization were divided into smaller pieces for flexible workflows. One of the features is that we may tailor various <code>filter_</code> conditions in individual steps, to remove inappropriate entries. Another example is that we may execute repetitively <code>standPep</code> and <code>standPrn</code> with different <code>slice_</code> conditions to achieve the mixed-bed normalization of data.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<blockquote>
<p>The modules of <code>purgePSM</code> and <code>purgePep</code> may be viewed as optional in that they do not add columns to the input datum.</p>
</blockquote>
<p>After peptide and protein normalization, we may apply <code>pepSig</code> and <code>prnSig</code> to calculate significance p-values. Methods based on long-run frequency interpretation of probability are used in these two modules.</p>
<p>The modules of <code>pepSig</code> and <code>prnSig</code>, which calculate significance p-values, are arguably part of the normalization steps. One benefit in having them early in the procedure is to allow data subsetting against p-values in downstream analyses. For instance, we may subset data by the lowest p-values for heat map visualization. In addition, <code>prnSig</code> is required for modules such as <code>prnGSPA</code> that uses protein p-values. For the quasi-essentiality, they were assigned to the normalization unit.</p>
<blockquote>
<p><em>NB</em>: every time sample(s) were <a href="https://proteoq.netlify.com/post/sample-exlusion-from-metadata/">voided</a> from <code>expt_smry.xlsx</code>, all the units in data normalization need to be re-executed to update the result files of <code>Peptide.txt</code>, <code>Protein.txt</code> etc. A cleaner alternative is to carry out the analysis from scratch as a brand new task.</p>
</blockquote>
</div>
<div id="informatic-analysis" class="section level2">
<h2>Informatic analysis</h2>
<p>The proteoQ modules in informatics can be executed more independently without specific orders. For instance, we may run from <code>GSEA</code> to <code>Heat map</code> or vice versa. It is also a valid idea to run alongside utilities under the same module. In the example of protein Trend analysis, it comprises the analysis part of <code>anal_prnTrend</code> and the visualization part of <code>plot_prnTrend</code>. We will need to first execute <code>anal_prnTrend</code>, and then <code>plot_prnTrend</code>.</p>
<div id="htmlwidget-2" style="width:800px;height:500px;" class="sankeyNetwork html-widget"></div>
<script type="application/json" data-for="htmlwidget-2">{"x":{"links":{"source":[0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,2,2,3,3,4,4,5,5,6,6,6,6,7,7,8,8,8,8,8,8,8,9,9,10,11,12,12,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,30,33,34,36,37,38,39,40,35,28,29,31,32,39,40,15,16,33,13,14,17,18,19,20,25,26,35,40,15,16,28,29,31,32,33,39],"target":[2,3,4,5,6,7,8,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,42,42,42,42,42,42,42,43,43,43,44,44,44,44,44,44,44,44,44,44,45,45,45,45,45,45,45,45],"value":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],"group":["Peptide","Peptide","Peptide","Peptide","Peptide","Peptide","Peptide","Protein","Protein","Protein","Protein","Protein","Protein","Protein","Protein","Protein","Protein","Protein",null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"filter","filter","filter","filter","filter","filter","filter","filter","filter","filter","filter","filter","filter","filter","filter","filter","filter","filter","filter","filter","filter","filter","filter","filter2","filter2","filter2","filter2","filter2","filter2","filter2","arrange","arrange","arrange","ggplot2","ggplot2","ggplot2","ggplot2","ggplot2","ggplot2","ggplot2","ggplot2","ggplot2","ggplot2","pheatmap","pheatmap","pheatmap","pheatmap","pheatmap","pheatmap","pheatmap","pheatmap"]},"nodes":{"name":["Peptide","Protein","Histogram","Heat map","MDS","PCA","Correlation","Volcano plot","NMF","Trend","GSEA","GSVA","GSPA","pepHist","prnHist","pepHM","prnHM","pepMDS","prnMDS","pepPCA","prnPCA","pepCorr_logFC","pepCorr_logInt","prnCorr_logFC","prnCorr_logInt","pepVol","prnVol","anal_pepNMF","plot_pepNMFCoef","plot_pepNMFCon","anal_prnNMF","plot_prnNMFCoef","plot_prnNMFCon","plot_metaNMF","anal_prnTrend","plot_prnTrend","prnGSEA","prnGSVA","prnGSPA","prnGSPAHM","gspaMap","filter_","filter2_","arrange_","ggplot2","pheatmap"],"group":["Peptide","Protein","Histogram","Heat map","MDS","PCA","Correlation","Volcano plot","NMF","Trend","GSEA","GSVA","GSPA","pepHist","prnHist","pepHM","prnHM","pepMDS","prnMDS","pepPCA","prnPCA","pepCorr_logFC","pepCorr_logInt","prnCorr_logFC","prnCorr_logInt","pepVol","prnVol","anal_pepNMF","plot_pepNMFCoef","plot_pepNMFCon","anal_prnNMF","plot_prnNMFCoef","plot_prnNMFCon","plot_metaNMF","anal_prnTrend","plot_prnTrend","prnGSEA","prnGSVA","prnGSPA","prnGSPAHM","gspaMap","filter_","filter2_","arrange_","ggplot2","pheatmap"]},"options":{"NodeID":"name","NodeGroup":"name","LinkGroup":"group","colourScale":"d3.scaleOrdinal(d3.schemeCategory20);","fontSize":11,"fontFamily":null,"nodeWidth":30,"nodePadding":10,"units":"TWh","margin":{"top":null,"right":null,"bottom":null,"left":null},"iterations":32,"sinksRight":true}},"evals":[],"jsHooks":[]}</script>
<p>Variable arguments (varargs) are broadly employed in proteoQ, typically for the purpose of flexible data row subsetting and ordering. The data files coming out of <code>Data normalization</code> are considered primary and termed <code>df</code>. We can then apply varargs of <code>filter_</code> and <code>arrange_</code> for utilities that read <code>df</code>. For example, <code>prnHM</code> imports the protein table, let’s say <code>Protein.txt</code>, and can take <code>filter_</code> and <code>arrange_</code> varargs for row filtration and ordering, respectively.</p>
<p>There are also utilities that read data files from informatic analysis. These files are termed secondary data files, <code>df2</code>. One example is <code>plot_prnNMFCon</code> that imports the consensus findings from <code>anal_prnNMF</code> for heat map visualization. The corresponding vararg for data filtration is <code>filter2_</code>.</p>
<p>The <code>gspaMap</code> is more unique in that it processes both <code>df</code>, the protein table from <code>Data normalization</code>, and <code>df2</code>, the gene set results from <code>prnGSPA</code>. Thus, it is possible to apply both <code>filter_</code> and <code>filter2_</code> when calling the module.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<p>The graphic visualization is typically facilitated through <code>ggplot2</code> or <code>pheatmap</code>, with the later being used exclusively for heat maps. Parameter passing via <code>dot-dot-dot</code> is generally applicable. To take advantage of the full-fledged <code>ggplot2</code>, results are exported when possible. In the following example, we pass the findings from <code>prnMDS</code> for external <code>ggplot2</code> visualization:</p>
<pre class="r"><code>library(ggplot2)
res &lt;- prnMDS()
p &lt;- ggplot(res) + ...</code></pre>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>See also the help documents in proteoQ and the online <a href="https://github.com/qzhang503/proteoQ">README</a><a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>See also <code>?proteoQ::gspaMap</code> for details.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
